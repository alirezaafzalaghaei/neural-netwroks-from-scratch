\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Multi layer perceptron \(MLP\)}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Forward phase}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Loss function}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Backward phase: Backpropagation}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Update phase}{section.2}% 6
\BOOKMARK [1][-]{section.3}{Regularization}{}% 7
\BOOKMARK [2][-]{subsection.3.1}{Weight regularization}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.2}{Dropout}{section.3}% 9
\BOOKMARK [1][-]{section.4}{Convolutional neural network \(CNN\)}{}% 10
\BOOKMARK [2][-]{subsection.4.1}{Convolution block}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.2}{Pooling block}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.3}{Backward phase}{section.4}% 13
\BOOKMARK [1][-]{section.5}{Recurrent neural network \(RNN\)}{}% 14
\BOOKMARK [2][-]{subsection.5.1}{LSTM}{section.5}% 15
\BOOKMARK [2][-]{subsection.5.2}{GRU}{section.5}% 16
\BOOKMARK [2][-]{subsection.5.3}{Bidirectional}{section.5}% 17
\BOOKMARK [2][-]{subsection.5.4}{Backward phase}{section.5}% 18
\BOOKMARK [1][-]{section.6}{Text analysis}{}% 19
\BOOKMARK [2][-]{subsection.6.1}{Embedding}{section.6}% 20
\BOOKMARK [1][-]{section.7}{Implementation}{}% 21
\BOOKMARK [2][-]{subsection.7.1}{MLP model}{section.7}% 22
\BOOKMARK [2][-]{subsection.7.2}{CNN Model}{section.7}% 23
\BOOKMARK [2][-]{subsection.7.3}{RNN Model}{section.7}% 24
\BOOKMARK [2][-]{subsection.7.4}{Hyperparameter tuning}{section.7}% 25
\BOOKMARK [1][-]{section.8}{Results and Discussion}{}% 26
\BOOKMARK [2][-]{subsection.8.1}{Iris}{section.8}% 27
\BOOKMARK [2][-]{subsection.8.2}{Statlog}{section.8}% 28
\BOOKMARK [2][-]{subsection.8.3}{mnist}{section.8}% 29
\BOOKMARK [2][-]{subsection.8.4}{Fashion mnist}{section.8}% 30
\BOOKMARK [2][-]{subsection.8.5}{Cifar10}{section.8}% 31
\BOOKMARK [2][-]{subsection.8.6}{Sentiment analysis}{section.8}% 32
\BOOKMARK [1][-]{section.9}{Concluding remarks}{}% 33
